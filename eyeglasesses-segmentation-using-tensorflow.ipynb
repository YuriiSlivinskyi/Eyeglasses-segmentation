{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8604068,"sourceType":"datasetVersion","datasetId":5148260}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Yurii Slivinskyi\n## Eyeglasses segmentation using U-Net architecture with TensorFLow","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:16:03.507588Z","iopub.execute_input":"2024-06-07T13:16:03.507856Z","iopub.status.idle":"2024-06-07T13:16:17.588353Z","shell.execute_reply.started":"2024-06-07T13:16:03.507831Z","shell.execute_reply":"2024-06-07T13:16:17.587543Z"}}},{"cell_type":"markdown","source":"# Table of content\n1. [Packages](#packages)\n2. [Data loading and observation](#data-loading-and-observation)\n3. [Model architecture](#model-architecture)\n4. [Model training](#model-training)\n5. [Model evaluation](#model-evaluation)\n6. [Comparing CPU and GPU](#comparing-cpu-and-gpu)","metadata":{}},{"cell_type":"markdown","source":"## Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\nimport os\nimport imageio.v2 as imageio","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:56:56.231547Z","iopub.execute_input":"2024-06-07T13:56:56.232496Z","iopub.status.idle":"2024-06-07T13:56:56.237254Z","shell.execute_reply.started":"2024-06-07T13:56:56.232459Z","shell.execute_reply":"2024-06-07T13:56:56.236304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loading and observation","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/eyeglasses-segmentation/eyeglasses_dataset/'\nIMG_SIZE = (512, 512, 3)\n\nimage_path = os.path.join(PATH, './train/images/')\nmask_path = os.path.join(PATH, './train/masks/')\nimage_list_orig = os.listdir(image_path)\nmask_list_orig = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list_orig]\nmask_list = [mask_path+i for i in mask_list_orig]\nimage_list.sort()\nmask_list.sort()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:56:57.347452Z","iopub.execute_input":"2024-06-07T13:56:57.348270Z","iopub.status.idle":"2024-06-07T13:56:57.366799Z","shell.execute_reply.started":"2024-06-07T13:56:57.348238Z","shell.execute_reply":"2024-06-07T13:56:57.366088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = imageio.imread(image_list[1])\nmask = imageio.imread(mask_list[1])\n\n\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(img)\narr[0].set_title('Image')\narr[1].imshow(mask)\narr[1].set_title('Segmentation')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:56:57.673384Z","iopub.execute_input":"2024-06-07T13:56:57.674122Z","iopub.status.idle":"2024-06-07T13:56:58.305787Z","shell.execute_reply.started":"2024-06-07T13:56:57.674092Z","shell.execute_reply":"2024-06-07T13:56:58.304817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Input data is images 512 x 512 and binary mask with classes eyeglasses / not eyeglasses. Despite all images are the same size it will be usefull to create preprocessing pipeline for the future use.","metadata":{}},{"cell_type":"code","source":"def process_path(image_path, mask_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=1)\n    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n    return img, mask","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:56:59.423564Z","iopub.execute_input":"2024-06-07T13:56:59.424182Z","iopub.status.idle":"2024-06-07T13:56:59.430110Z","shell.execute_reply.started":"2024-06-07T13:56:59.424147Z","shell.execute_reply":"2024-06-07T13:56:59.429092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(image, mask):\n    input_image = tf.image.resize(image, IMG_SIZE[:2], method='nearest')\n    input_mask = tf.image.resize(mask, IMG_SIZE[:2], method='nearest')\n    input_mask /= 255\n\n    return input_image, input_mask","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:56:59.633286Z","iopub.execute_input":"2024-06-07T13:56:59.633574Z","iopub.status.idle":"2024-06-07T13:56:59.638677Z","shell.execute_reply.started":"2024-06-07T13:56:59.633549Z","shell.execute_reply":"2024-06-07T13:56:59.637787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(path, subset):\n    image_path = os.path.join(path, f'./{subset}/images/')\n    mask_path = os.path.join(path, f'./{subset}/masks/')\n    image_list_orig = os.listdir(image_path)\n    mask_list_orig = os.listdir(mask_path)\n    image_list = [image_path+i for i in image_list_orig]\n    mask_list = [mask_path+i for i in mask_list_orig]\n    image_list.sort()\n    mask_list.sort()\n    print(f'Number of {subset} examples: {len(image_list)}')\n    \n    image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\n    mask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)\n    \n    image_filenames = tf.constant(image_list)\n    masks_filenames = tf.constant(mask_list)\n\n    dataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n    \n    image_ds = dataset.map(process_path)\n\n    return image_ds.map(preprocess)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:56:59.860875Z","iopub.execute_input":"2024-06-07T13:56:59.861252Z","iopub.status.idle":"2024-06-07T13:56:59.868895Z","shell.execute_reply.started":"2024-06-07T13:56:59.861224Z","shell.execute_reply":"2024-06-07T13:56:59.868064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = load_data(PATH, 'train')\nval = load_data(PATH, 'val')\ntest = load_data(PATH, 'test')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:57:00.951117Z","iopub.execute_input":"2024-06-07T13:57:00.952000Z","iopub.status.idle":"2024-06-07T13:57:01.116555Z","shell.execute_reply.started":"2024-06-07T13:57:00.951960Z","shell.execute_reply":"2024-06-07T13:57:01.115460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model architecture","metadata":{}},{"cell_type":"markdown","source":"I will be using standart U-Net architecture with first encodeing and then decoding layers. As an encoder I'll use pretrained model - MobileNetV2. From encoder will be 5 skip connection to decoder. That will allow model learn complex features not only depth-wise, but resolution-wise too. Also that will help with vanishing/exploding gradient.\nDecoding layers will have this structure:\n- Concatenation of previous layer outputs with outputs skip connection from encoder\n- Transpose convolution to double output width and height\n- Two layers of normal convolution with same padding\nAfter decoding process output will be followed with 1x1 convolution layer to get the final output of shape 512x512x2, where will be displayed result for each pixel and logits for classes eyeglasses / not eyeglasses","metadata":{}},{"cell_type":"code","source":"def decoder(input, skip, n_filters=64):\n    tmp = input\n    tmp = tfl.Concatenate()([tmp, skip])\n    tmp = tfl.Conv2DTranspose(filters=n_filters, kernel_size=3, strides=2, padding='same', kernel_initializer='he_normal')(tmp)\n    tmp = tfl.Conv2D(n_filters//2, 2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')(tmp)\n    tmp = tfl.Conv2D(n_filters, 2, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')(tmp)\n    return tmp\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:24:22.672765Z","iopub.execute_input":"2024-06-07T13:24:22.673150Z","iopub.status.idle":"2024-06-07T13:24:22.679566Z","shell.execute_reply.started":"2024-06-07T13:24:22.673117Z","shell.execute_reply":"2024-06-07T13:24:22.678611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet(input_shape=(512, 512, 3), n_classes=2):\n    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False)\n\n    skip_connections = [\n        'block_1_expand_relu',   \n        'block_3_expand_relu',   \n        'block_6_expand_relu',   \n        'block_13_expand_relu',  \n        'block_16_project',      \n    ]\n    base_model_outputs = [base_model.get_layer(name).output for name in skip_connections]\n    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n    down_stack.trainable = False\n    \n    inputs = tf.keras.layers.Input(shape=input_shape)\n\n    skips = down_stack(inputs)\n    x = skips[-1]\n    \n    for  i, skip in enumerate(skips[::-1]):\n        x = decoder(x, skip, n_filters=16 * (2 ** i))\n    \n    x = tf.keras.layers.Conv2D(\n      filters=n_classes, kernel_size=1, strides=1,\n      padding='same')(x)\n    \n    return tf.keras.Model(inputs=inputs, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:24:24.209850Z","iopub.execute_input":"2024-06-07T13:24:24.210537Z","iopub.status.idle":"2024-06-07T13:24:24.218413Z","shell.execute_reply.started":"2024-06-07T13:24:24.210507Z","shell.execute_reply":"2024-06-07T13:24:24.217392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For loss function we'll be using SparseCategoricalCrossentropy. \\\nAs main perfomance I chosed Mean Intersection over Union. Giving the high class imbalance in each image metric needs to be robust to that class imbalance. \nMeanIoU calculated as $ \\frac{TP}{TP + FP + FN} $, where TP is a number of true positives, FP - number of false positives and FN is number of false negatieves. This metric allows us to correctly evaluate model's perfomance, despite class imbalance. \\ \nAs optimisation algorithm we will use ADAM with learning rate of 0.001.","metadata":{}},{"cell_type":"code","source":"N_CLASSES = 2\n\nmodel = unet(input_shape=IMG_SIZE,n_classes=N_CLASSES)\nmodel.compile(optimizer='adam',\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[tf.keras.metrics.MeanIoU(num_classes=2, sparse_y_pred=False),'accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:24:47.863428Z","iopub.execute_input":"2024-06-07T13:24:47.863757Z","iopub.status.idle":"2024-06-07T13:24:49.636205Z","shell.execute_reply.started":"2024-06-07T13:24:47.863732Z","shell.execute_reply":"2024-06-07T13:24:49.635438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:24:49.637832Z","iopub.execute_input":"2024-06-07T13:24:49.638530Z","iopub.status.idle":"2024-06-07T13:24:49.694566Z","shell.execute_reply.started":"2024-06-07T13:24:49.638494Z","shell.execute_reply":"2024-06-07T13:24:49.693785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"markdown","source":"Because more than a half of out model is pretrained, we will use small number of epoch and later we always can do more epochs. Also we will use early stopping to prevent overtraining of our model.","metadata":{}},{"cell_type":"code","source":"EPOCHS = 15\nBATCH_SIZE = 8\ntrain_dataset = train.cache().shuffle(buffer_size=1000).batch(BATCH_SIZE)\nvalidation_dataset = val.batch(BATCH_SIZE)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    min_delta=1e-6,\n                                                    patience=4,\n                                                    verbose=1)\n\nmodel_history = model.fit(train_dataset, epochs=EPOCHS,\n                         validation_data=validation_dataset,\n                         callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T16:42:12.570644Z","iopub.execute_input":"2024-06-06T16:42:12.571549Z","iopub.status.idle":"2024-06-06T17:41:59.482723Z","shell.execute_reply.started":"2024-06-06T16:42:12.571509Z","shell.execute_reply":"2024-06-06T17:41:59.481588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Metric on training and validation data are looking pretty good. Let's look at trainig info and some examples from validation set.","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(11, 11))\naxs = axs.ravel()\n\nfor id, value in enumerate(model_history.history):\n    axs[id].plot(model_history.history[value])\n    axs[id].set(title=value)\n\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T17:46:57.123998Z","iopub.execute_input":"2024-06-06T17:46:57.124668Z","iopub.status.idle":"2024-06-06T17:46:58.488774Z","shell.execute_reply.started":"2024-06-06T17:46:57.124636Z","shell.execute_reply":"2024-06-06T17:46:58.487684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation","metadata":{}},{"cell_type":"markdown","source":"Training perfomance is more smoother tha validation, but it's ok","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:51:52.976960Z","iopub.execute_input":"2024-06-07T13:51:52.977466Z","iopub.status.idle":"2024-06-07T13:51:52.985347Z","shell.execute_reply.started":"2024-06-07T13:51:52.977422Z","shell.execute_reply":"2024-06-07T13:51:52.983899Z"}}},{"cell_type":"code","source":"def create_mask(pred_mask):\n    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:08:03.928469Z","iopub.execute_input":"2024-06-07T14:08:03.929213Z","iopub.status.idle":"2024-06-07T14:08:03.933996Z","shell.execute_reply.started":"2024-06-07T14:08:03.929177Z","shell.execute_reply":"2024-06-07T14:08:03.932957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    fig, axs = plt.subplots(ncols=3, figsize=(15,15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n    iou = tf.metrics.MeanIoU(num_classes=2)(display_list[1], display_list[2])\n    ac = tf.metrics.Accuracy()(display_list[1], display_list[2])\n    stats = f\" IoU: {iou: .3f}\\nAccuracy: {ac: .3f}\"\n\n    for i in range(len(display_list)):\n        axs[i].set(title = title[i])\n        axs[i].imshow(tf.keras.utils.array_to_img(display_list[i]))\n        \n        axs[i].axis('off')\n    axs[2].text(\n            0.05, 0.95,\n            stats,\n            transform=axs[2].transAxes,\n            fontsize=10,\n            verticalalignment='top',\n            bbox=dict(boxstyle='round', facecolor='#f994a6', alpha=0.5)\n        )\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:08:04.230673Z","iopub.execute_input":"2024-06-07T14:08:04.231517Z","iopub.status.idle":"2024-06-07T14:08:04.239864Z","shell.execute_reply.started":"2024-06-07T14:08:04.231479Z","shell.execute_reply":"2024-06-07T14:08:04.238764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predictions(dataset, num=1):\n    for image, mask in dataset.take(num):\n        pred_mask = model.predict(image)\n        display([image[0], mask[0], create_mask(pred_mask)])","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:08:04.951149Z","iopub.execute_input":"2024-06-07T14:08:04.951865Z","iopub.status.idle":"2024-06-07T14:08:04.956601Z","shell.execute_reply.started":"2024-06-07T14:08:04.951836Z","shell.execute_reply":"2024-06-07T14:08:04.955695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset = val.shuffle(100).batch(1)\nshow_predictions(validation_dataset, 5)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T18:51:26.112206Z","iopub.execute_input":"2024-06-06T18:51:26.112588Z","iopub.status.idle":"2024-06-06T18:51:29.969822Z","shell.execute_reply.started":"2024-06-06T18:51:26.112561Z","shell.execute_reply":"2024-06-06T18:51:29.968798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the prediction I can say that perfomance are pretty good, but there are small problems with eyebrows and generally dark images. ","metadata":{}},{"cell_type":"code","source":"test_dataset = test.batch(1)\nshow_predictions(test_dataset, 10)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:08:08.244679Z","iopub.execute_input":"2024-06-07T14:08:08.245271Z","iopub.status.idle":"2024-06-07T14:08:27.571543Z","shell.execute_reply.started":"2024-06-07T14:08:08.245237Z","shell.execute_reply":"2024-06-07T14:08:27.570685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test results are good aswell, but there are a problem with half-transparent eyeglasses, but I am satisfied with the results.","metadata":{}},{"cell_type":"code","source":"model.save('model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T18:50:53.753475Z","iopub.execute_input":"2024-06-06T18:50:53.754146Z","iopub.status.idle":"2024-06-06T18:50:54.280588Z","shell.execute_reply.started":"2024-06-06T18:50:53.754114Z","shell.execute_reply":"2024-06-06T18:50:54.279571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparing CPU and GPU ","metadata":{}},{"cell_type":"markdown","source":"Now let's compare how long it takes for that model to predict entire test set on CPU(Intel Xeon 2.20 GHz) and GPU(Nvidia Tesla P100)","metadata":{}},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:01:40.489301Z","iopub.execute_input":"2024-06-07T14:01:40.489986Z","iopub.status.idle":"2024-06-07T14:01:40.494634Z","shell.execute_reply.started":"2024-06-07T14:01:40.489949Z","shell.execute_reply":"2024-06-07T14:01:40.493575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def time_predictions(func):\n    def wrapper(*args, **kwargs): \n        start = time.perf_counter()\n        func(*args, **kwargs)\n        end = time.perf_counter() -start\n        print(f'Time taken: {end}\\n')\n        return\n    return wrapper","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:11:14.092506Z","iopub.execute_input":"2024-06-07T14:11:14.093229Z","iopub.status.idle":"2024-06-07T14:11:14.098256Z","shell.execute_reply.started":"2024-06-07T14:11:14.093195Z","shell.execute_reply":"2024-06-07T14:11:14.097321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@time_predictions\ndef make_predictions(dataset, device, num=10):\n    print(f'Making predictions using {device}')\n    with tf.device('/'+device+':0'):\n        for image, mask in dataset.take(num):\n            model(image)\n    return","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:26:58.454811Z","iopub.execute_input":"2024-06-07T14:26:58.455211Z","iopub.status.idle":"2024-06-07T14:26:58.460749Z","shell.execute_reply.started":"2024-06-07T14:26:58.455179Z","shell.execute_reply":"2024-06-07T14:26:58.459638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_predictions(test_dataset, 'GPU')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:26:59.290682Z","iopub.execute_input":"2024-06-07T14:26:59.291537Z","iopub.status.idle":"2024-06-07T14:27:03.778796Z","shell.execute_reply.started":"2024-06-07T14:26:59.291503Z","shell.execute_reply":"2024-06-07T14:27:03.777642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_predictions(test_dataset, 'CPU')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:27:07.022628Z","iopub.execute_input":"2024-06-07T14:27:07.022981Z","iopub.status.idle":"2024-06-07T14:27:28.969576Z","shell.execute_reply.started":"2024-06-07T14:27:07.022955Z","shell.execute_reply":"2024-06-07T14:27:28.968626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are clearly a big difference at execution speed","metadata":{}}]}